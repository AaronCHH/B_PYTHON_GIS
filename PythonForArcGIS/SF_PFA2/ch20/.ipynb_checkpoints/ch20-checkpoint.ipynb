{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 Working with HTML and KML\n",
    "* 20.1 Working with HTML\n",
    "  * 20.1.1 Specifying Links\n",
    "  * 20.1.2 Embedding Images\n",
    "  * 20.1.3 HTML Lists\n",
    "  * 20.1.4 HTML Tables\n",
    "  * 20.1.5 Writing HTML with Python\n",
    "  * 20.1.6 Parsing HTML with BeautifulSoup\n",
    "* 20.2 Fetching and Uncompressing Data\n",
    "  * 20.2.1 Fetching HTML\n",
    "  * 20.2.2 Fetching Compressed Data\n",
    "  * 20.2.3 Expanding Compressed Data\n",
    "* 20.3 Working with\n",
    "  * 20.3.1 The Structure of KML\n",
    "  * 20.3.2 Parsing\n",
    "  * 20.3.3 Converting KML to Shapefile\n",
    "* 20.4 Discussion\n",
    "* 20.5 Key Terms\n",
    "* 20.6 Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.1 Working with HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.1 Specifying Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.2 Embedding Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.3 HTML Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.4 HTML Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.5 Writing HTML with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/writeSimpleHTML.py\n",
    "# writeSimpleHTML.py\n",
    "# Purpose: Write HTML page from hard-coded string.\n",
    "# Usage: No arguments needed.\n",
    "\n",
    "mystr = '''<!DOCTYPE html>\n",
    "<html>\n",
    "    <body>\n",
    "        <h1>Asian Elephant</h1>\n",
    "        <img src=\"../data/ch20/pics/lakshmi.jpg\" alt=\"elephant\">\n",
    "    </body>\n",
    "</html>\n",
    "'''\n",
    "htmlFile = 'C:/gispy/scratch/output.html'\n",
    "outf = open(htmlFile, 'w')\n",
    "outf.write(mystr)\n",
    "outf.close()\n",
    "print '{0} created.'.format(htmlFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch/output.html created.\n"
     ]
    }
   ],
   "source": [
    "%run script2/writeSimpleHTML.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load script/writeSimpleHTML2.py\n",
    "# writeSimpleHTML2.py\n",
    "# Purpose: Write HTML page in 3 parts.\n",
    "# Usage: workspace title image_path\n",
    "# Example input: C:/gispy/scratch \"Asian Elephant\" ../data/ch20/pics/lakshmi.jpg\n",
    "import sys\n",
    "workspace = sys.argv[1]\n",
    "title = sys.argv[2]\n",
    "image = sys.argv[3]\n",
    "\n",
    "beginning = '''<!DOCTYPE html>\n",
    "<html>\n",
    "    <body>'''\n",
    "\n",
    "middle = '''\n",
    "        <h1>{0}</h1>\n",
    "        <img src='{1}' >\\n'''.format(title, image)\n",
    "\n",
    "end = '''   </body>\n",
    "</html>\n",
    "'''\n",
    "\n",
    "htmlfile = workspace + '/output2.html'\n",
    "with open(htmlfile, 'w') as outf:\n",
    "    outf.write(beginning)\n",
    "    outf.write(middle)\n",
    "    outf.write(end)\n",
    "\n",
    "print '{0} created.'.format(htmlfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch/output2.html created.\n"
     ]
    }
   ],
   "source": [
    "%run script/writeSimpleHTML2.py scratch \"Asian Elephant\" ../data/pics/lakshmi.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/printHTMLList.py\n",
    "# printHTMLList.py\n",
    "# Purpose: Call a function that converts\n",
    "#           a Python list to an HTML list.\n",
    "\n",
    "\n",
    "def python2htmlList(myList, listType, attrs=''):\n",
    "    '''Convert a Python list to HTML list.\n",
    "    For example, convert [rast1,rast2] to:\n",
    "    <ul>\n",
    "       <li>rast1</li>\n",
    "       <li>rast2</li>\n",
    "    </ul>\n",
    "    '''\n",
    "    # Wrap items in item tags.\n",
    "    htmlItems = ['<li>' + str(item) + '</li>' for item in myList]\n",
    "\n",
    "    # Join the item list into a string with a line break after each item.\n",
    "    itemsString = '''\\n        '''.join(htmlItems)\n",
    "\n",
    "    # Wrap the string of items in the list tag.\n",
    "    htmlList = '''\n",
    "    <{0} {1}>\n",
    "        {2}\n",
    "    </{0}>\n",
    "    '''.format(listType, attrs, itemsString)\n",
    "    return htmlList\n",
    "\n",
    "rasts = [u'elev', u'landcov', u'soilsid', u'getty_cover']\n",
    "htmlList = python2htmlList(rasts, 'ul')\n",
    "print htmlList\n",
    "\n",
    "htmlList2 = python2htmlList(rasts, 'ol')\n",
    "print htmlList2\n",
    "\n",
    "htmlList3 = python2htmlList(rasts, 'ol', 'type=\"a\"')\n",
    "print htmlList3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    <ul >\n",
      "        <li>elev</li>\n",
      "        <li>landcov</li>\n",
      "        <li>soilsid</li>\n",
      "        <li>getty_cover</li>\n",
      "    </ul>\n",
      "    \n",
      "\n",
      "    <ol >\n",
      "        <li>elev</li>\n",
      "        <li>landcov</li>\n",
      "        <li>soilsid</li>\n",
      "        <li>getty_cover</li>\n",
      "    </ol>\n",
      "    \n",
      "\n",
      "    <ol type=\"a\">\n",
      "        <li>elev</li>\n",
      "        <li>landcov</li>\n",
      "        <li>soilsid</li>\n",
      "        <li>getty_cover</li>\n",
      "    </ol>\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "%run script2/printHTMLList.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.1.6 Parsing HTML with BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('script')\n",
    "import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mystr = '<!DOCTYPE html><html><body><h1>Asian Elephant</h1><img src=\"lakshmi.jpg\" alt=\"elephant\"></body></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup.BeautifulSoup(mystr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <body>\n",
      "  <h1>\n",
      "   Asian Elephant\n",
      "  </h1>\n",
      "  <img src=\"lakshmi.jpg\" alt=\"elephant\" />\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "h = soup.prettify()\n",
    "print h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h1>Asian Elephant</h1>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = soup.find('h1')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BeautifulSoup.Tag"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'h1'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t.attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Asian Elephant']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Asian Elephant'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img src=\"lakshmi.jpg\" alt=\"elephant\" />"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = soup.find('img')\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'src', u'lakshmi.jpg'), (u'alt', u'elephant')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'lakshmi.jpg'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'elephant'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2['alt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: src Value: lakshmi.jpg\n",
      "Name: alt Value: elephant\n"
     ]
    }
   ],
   "source": [
    "for name, value in t2.attrs:\n",
    "  print 'Name: ' + name + ' Value: ' + value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "htmlList = '\\n <ul>\\n <li>elev</li>\\n <li>landcov</li>\\n<li>soilsid</li>\\n <li>getty_cover</li>\\n </ul>\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<ul>\n",
       "<li>elev</li>\n",
       "<li>landcov</li>\n",
       "<li>soilsid</li>\n",
       "<li>getty_cover</li>\n",
       "</ul>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup2 = BeautifulSoup.BeautifulSoup(htmlList)\n",
    "soup2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>elev</li>, <li>landcov</li>, <li>soilsid</li>, <li>getty_cover</li>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = soup2.findAll('li')\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elev\n",
      "landcov\n",
      "soilsid\n",
      "getty_cover\n"
     ]
    }
   ],
   "source": [
    "for t in tags:\n",
    "  print t.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-34-38a3b9dab961>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-34-38a3b9dab961>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Link: elephant1.html\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Link: elephant1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/getLinks.py\n",
    "# getLinks.py\n",
    "# Purpose: Read and print the links in an html file.\n",
    "\n",
    "import sys\n",
    "basedir = 'C:/gispy/'\n",
    "sys.path.append(basedir + 'sample_scripts/ch20')\n",
    "import BeautifulSoup\n",
    "\n",
    "# Read the HTML file contents.\n",
    "with open(basedir + 'data/ch20/htmlExamplePages/elephant2.html', 'r') as infile:\n",
    "\n",
    "    # Create a soup object and find all the hyperlinks.\n",
    "    soup = BeautifulSoup.BeautifulSoup(infile)\n",
    "    linkTags = soup.findAll('a')\n",
    "\n",
    "    # Print each hyperlink reference.\n",
    "    for linkTag in linkTags:\n",
    "        print 'Link: {0}'.format(linkTag['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link: elephant1.html\n",
      "Link: https://www.google.com/\n"
     ]
    }
   ],
   "source": [
    "%run script2/getLinks.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.2 Fetching and Uncompressing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.1 Fetching HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/fetchHTML.py\n",
    "# fetchHTML.py\n",
    "# Fetch HTML from a site and print the number of lines in the HTML\n",
    "import urllib2\n",
    "\n",
    "url = 'http://www.google.com'\n",
    "response = urllib2.urlopen(url)\n",
    "contents = response.read()\n",
    "response.close()\n",
    "print 'This page has {0} characters.'.format(len(contents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This page has 10486 characters.\n"
     ]
    }
   ],
   "source": [
    "%run script2/fetchHTML.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img src=\"../pics/lakshmi.jpg\" width=\"32\" height=\"32\" />]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pics = soup.findAll('img')\n",
    "pics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.2 Fetching Compressed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/fetchZip.py\n",
    "# fetchZip.py\n",
    "# Purpose: Fetch a zip file and place it in an output directory.\n",
    "import os, urllib2\n",
    "\n",
    "\n",
    "def fetchZip(url, outputDir):\n",
    "    '''Fetch binary web content located at 'url'\n",
    "    and write it in the output directory'''\n",
    "    response = urllib2.urlopen(url)\n",
    "    binContents = response.read()\n",
    "    response.close()\n",
    "\n",
    "    # Save zip file to output dir (write it in 'wb' mode).\n",
    "    outFileName = outputDir + os.path.basename(url)\n",
    "    with open(outFileName, 'wb') as outf:\n",
    "        outf.write(binContents)\n",
    "\n",
    "outputDir = 'C:/gispy/scratch/'\n",
    "theURL = 'file:///C:/gispy/data/ch20/getty.zip'\n",
    "fetchZip(theURL, outputDir)\n",
    "print '{0}{1} created.'.format(outputDir, os.path.basename(theURL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch/getty.zip created.\n"
     ]
    }
   ],
   "source": [
    "%run script2/fetchZip.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.2.3 Expanding Compressed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/extractFiles.py\n",
    "# extractFiles.py\n",
    "# Purpose: Extract files from an archive;\n",
    "#     Place the files into an output directory.\n",
    "# Usage: No script arguments\n",
    "\n",
    "import os, zipfile\n",
    "\n",
    "\n",
    "def unzipArchive(archiveName, dest):\n",
    "    '''Extract files from an archive\n",
    "    and save them in the destination directory'''\n",
    "    print 'Unzip {0} to {1}'.format(archiveName, dest)\n",
    "    # Get a Zipfile object.\n",
    "    with zipfile.ZipFile(archiveName, 'r') as zipObj:\n",
    "        zipObj.extractall(dest)\n",
    "        # Report the list of files extracted from the archive.\n",
    "        archiveList = zipObj.namelist()\n",
    "        for fileName in archiveList:\n",
    "            print ' Extract file: {0} ...'.format(fileName)\n",
    "    print 'Extraction complete.'\n",
    "\n",
    "archive = 'park.zip'\n",
    "baseDir = 'C:/gispy/'\n",
    "archiveFullName = baseDir + 'data/ch20/' + archive\n",
    "destination = baseDir + 'scratch/' + os.path.splitext(archive)[0] + '/'\n",
    "if not os.path.exists(destination):\n",
    "    os.makedirs(destination)\n",
    "unzipArchive(archiveFullName, destination)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzip data/park.zip to scratch/park/\n",
      " Extract file: park.prj ...\n",
      " Extract file: park.sbn ...\n",
      " Extract file: park.sbx ...\n",
      " Extract file: park.shp ...\n",
      " Extract file: park.shp.xml ...\n",
      " Extract file: park.shx ...\n",
      " Extract file: park.dbf ...\n",
      " Extract file: park.kmz ...\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "%run script2/extractFiles.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'script/restaurants.kml' was not found in history, as a file, url, nor in the user namespace.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-a268e6bed7d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'load script/restaurants.kml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\arcgis10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\arcgis10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-46>\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, arg_s)\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\arcgis10.1\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\arcgis10.1\\lib\\site-packages\\IPython\\core\\magics\\code.pyc\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0msearch_ns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'n'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_user_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_ns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msearch_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m's'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\arcgis10.1\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mfind_user_code\u001b[1;34m(self, target, raw, py_only, skip_encoding_cookie, search_ns)\u001b[0m\n\u001b[0;32m   3184\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3185\u001b[0m             raise ValueError((\"'%s' was not found in history, as a file, url, \"\n\u001b[1;32m-> 3186\u001b[1;33m                                 \"nor in the user namespace.\") % target)\n\u001b[0m\u001b[0;32m   3187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3188\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodeobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'script/restaurants.kml' was not found in history, as a file, url, nor in the user namespace."
     ]
    }
   ],
   "source": [
    "%load script/restaurants.kml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.3 Working with KML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.1 The Structure of KML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.2 Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/parseKMLrestaurants.py\n",
    "# parseKMLrestaurants.py\n",
    "# Purpose: Print kml placemark names and descriptions.\n",
    "import sys\n",
    "\n",
    "baseDir = 'C:/gispy/'\n",
    "sys.path.append(baseDir + 'sample_scripts/ch20')\n",
    "import BeautifulSoup\n",
    "\n",
    "fileName = baseDir + 'data/ch20/restaurants.kml'\n",
    "\n",
    "# Get the KML soup.\n",
    "with open(fileName, 'r') as kmlCode:\n",
    "    soup = BeautifulSoup.BeautifulSoup(kmlCode)\n",
    "\n",
    "# Print the names and descriptions.\n",
    "names = soup.findAll('name')\n",
    "descriptions = soup.findAll('description')\n",
    "for name, description in zip(names, descriptions):\n",
    "    print name.contents[0]\n",
    "    print '\\t{0}'.format(description.contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bubba's Tofu Gumbo\n",
      "\t[u'Tofu Gumbo and Zydeco!', <br />, u'Score: 97']\n",
      "Joe Bob's Good Cookin'\n",
      "\t[u\"The best tree top grits n' greens restaurant south of the Mason-Dixon line.\", <br />, u'Score: 94']\n"
     ]
    }
   ],
   "source": [
    "%run script2/parseKMLrestaurants.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"The best tree top grits n' greens restaurant south of the Mason-Dixon line.\",\n",
       " <br />,\n",
       " u'Score: 94']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Score: 94'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreString = description.contents[2]\n",
    "scoreString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'Score', u' 94']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreList = scoreString.split(':')\n",
    "scoreList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = float(scoreList[1])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20.3.3 Converting KML to Shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load script/restaurantKML2shp.py\n",
    "# restaurantKML2shp.py\n",
    "# Purpose: Create a shapefile from a kml file using an insert cursor.\n",
    "# Usage: kml_directory output_directory\n",
    "# Example input: C:/gispy/data/ch20 C:/gispy/scratch/\n",
    "\n",
    "import arcpy, os, sys, BeautifulSoup\n",
    "\n",
    "dataDir = sys.argv[1]\n",
    "outDir = sys.argv[2]\n",
    "arcpy.env.workspace = outDir\n",
    "kmlFile = 'restaurants.kml'\n",
    "kmlPath = os.path.join(dataDir, kmlFile)\n",
    "baseName = os.path.splitext(kmlFile)[0]\n",
    "fc = baseName + '.shp'\n",
    "\n",
    "fieldNames = ['name', 'blurb', 'score']\n",
    "fieldTypes = ['TEXT', 'TEXT', 'FLOAT']\n",
    "\n",
    "# If the shapefile already been created, delete it.\n",
    "if arcpy.Exists(fc):\n",
    "    arcpy.Delete_management(fc)\n",
    "\n",
    "sr = arcpy.SpatialReference('NAD 1983 UTM Zone 17N')\n",
    "arcpy.CreateFeatureclass_management(outDir, fc, 'POINT', '#', '#', '#', sr)\n",
    "for field, type in zip(fieldNames, fieldTypes):\n",
    "    arcpy.AddField_management(fc, field, type)\n",
    "\n",
    "# Get the tag soup.\n",
    "with open(kmlPath, 'r') as kmlCode:\n",
    "    soup = BeautifulSoup.BeautifulSoup(kmlCode)\n",
    "coordinates = soup.findAll('coordinates')\n",
    "names = soup.findAll('name')\n",
    "descriptions = soup.findAll('description')\n",
    "\n",
    "# Populate the shapefile.\n",
    "with arcpy.da.InsertCursor(fc, ['SHAPE@XY'] + fieldNames) as ic:\n",
    "    for c, n, d in zip(coordinates, names, descriptions):\n",
    "        # Get field values.\n",
    "        [x, y, z] = c.contents[0].split(',')\n",
    "        myPoint = arcpy.Point(x, y)\n",
    "        name = n.contents[0]\n",
    "        blurb = d.contents[0]\n",
    "        scoreString = d.contents[2]\n",
    "        scoreList = scoreString.split(':')\n",
    "        score = float(scoreList[1])\n",
    "        # Put row values in a list & insert the new row.\n",
    "        newRow = [myPoint, name, blurb, score]\n",
    "        ic.insertRow(newRow)\n",
    "print '{0}{1} created.'.format(outDir, fc)\n",
    "if ic:\n",
    "    del ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scratch/restaurants.shp created.\n"
     ]
    }
   ],
   "source": [
    "%run script2/restaurantKML2shp.py data scratch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.4 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.5 Key Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20.6 Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
